{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec113f8e-56c1-44f7-9571-292c946bb6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, json, os, sys\n",
    "\n",
    "sys.path.append('/path/to/metrics/') # TODO: Replace with path to `SWE-bench/metrics` folder\n",
    "from conversion import convert_log_to_ground_truth\n",
    "from monitor import monitor_validation, monitor_logs_same_diff\n",
    "sys.path = sys.path[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e965b7-702e-49d4-bc15-2619dc185752",
   "metadata": {},
   "source": [
    "Declare repository; Fetch tasks, logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f1e9497-6e60-4027-8cee-790c8d0f1886",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = 'keras_team/keras' # TODO: Replace with repository name\n",
    "log_dir = '/home/manhtd/Projects/logs-viewer/logs' # TODO: Replace with path to folder of execution logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf69ebd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def load_jsonl(file_path):\n",
    "    \"\"\"\n",
    "    Loads a .jsonl file and returns a list of JSON objects.\n",
    "\n",
    "    Parameters:\n",
    "        file_path (str): The path to the .jsonl file.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of dictionaries or lists, each representing a JSON object.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            data.append(json.loads(line))\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba9ae3b-726c-40ec-8ed2-4012fc4f70dc",
   "metadata": {},
   "source": [
    "Get map of version to setup commit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "daa9d915-da85-4ca0-bba1-cd61ffeef3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = load_jsonl('/home/manhtd/Projects/SWE-Python-AI/collect/output/keras-task-instances.jsonl') # TODO: Replace with path to versioned candidate task instances\n",
    "tasks = sorted(tasks, key=lambda x: x['created_at'], reverse=True)\n",
    "version_to_setup_commit = {}\n",
    "for t in tasks:\n",
    "    if 'version' in t and t['version'] not in version_to_setup_commit:\n",
    "        version_to_setup_commit[t['version']] = t['base_commit']\n",
    "assert(\n",
    "    sorted(list([x or \"\" for x in version_to_setup_commit.keys()])) ==\n",
    "    sorted(list(set([t['version'] or \"\" for t in tasks if 'version' in t])))\n",
    ")\n",
    "tasks = {t['instance_id']: t for t in tasks}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0994a4a9-fd3d-4554-90b7-24b10c499b8a",
   "metadata": {},
   "source": [
    "#### Monitor Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5fcd54c-1a45-41f9-8a9c-64e9ff9df31a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Attempts: 116\n",
      "Failed: 32\n",
      "Usable: 84\n",
      "Corrupt Test: 0\n",
      "Corrupt Diff: 0\n",
      "Test Script Timeout: 0\n",
      "Success E2E: 84\n"
     ]
    }
   ],
   "source": [
    "failed_install, corrupt_test_patch, corrupt_patch, timeout, success = monitor_validation(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecf576b3-22ed-4d8c-a40d-340ae8c56db8",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'keras-team/keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m logs_same, logs_diff \u001b[38;5;241m=\u001b[39m \u001b[43mmonitor_logs_same_diff\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlog_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLogs same: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(logs_same)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLogs diff: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(logs_diff)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Projects/My-SWE-bench/metrics/monitor.py:106\u001b[0m, in \u001b[0;36mmonitor_logs_same_diff\u001b[0;34m(log_dir, repo)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;66;03m# Get repo from log file path\u001b[39;00m\n\u001b[1;32m    105\u001b[0m     repo \u001b[38;5;241m=\u001b[39m get_repo_from_lp(log_fp)\n\u001b[0;32m--> 106\u001b[0m     log_parser \u001b[38;5;241m=\u001b[39m \u001b[43mMAP_REPO_TO_PARSER\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrepo\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    108\u001b[0m sms, found \u001b[38;5;241m=\u001b[39m log_path_to_sms(log_fp, log_parser)\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m found:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'keras-team/keras'"
     ]
    }
   ],
   "source": [
    "logs_same, logs_diff = monitor_logs_same_diff(log_dir)\n",
    "print(f\"Logs same: {len(logs_same)}\")\n",
    "print(f\"Logs diff: {len(logs_diff)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81a74a5-c56e-4724-acf5-378b601a2d89",
   "metadata": {},
   "source": [
    "#### Get [FP]2[FP] Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504d3ba5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb935466-43e8-45a7-8f46-15925d82312b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inst_id_to_gt = {}\n",
    "for d in logs_diff:\n",
    "    status_gt = convert_log_to_ground_truth(d[0])\n",
    "    inst_id_to_gt[d[0]] = status_gt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccaa7863-f144-49da-ae92-6430841bd3ea",
   "metadata": {},
   "source": [
    "#### Create Task Instances `.json` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a992349a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def dump_jsonl(data, file_path):\n",
    "    \"\"\"\n",
    "    Dumps a list of JSON objects to a .jsonl file.\n",
    "\n",
    "    Parameters:\n",
    "        data (list): A list of dictionaries or lists to write to the file, where each item will be a line.\n",
    "        file_path (str): The path to the .jsonl file to write to.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    with open(file_path, 'w') as file:\n",
    "        for item in data:\n",
    "            # Convert each item to a JSON string and write it as a new line\n",
    "            file.write(json.dumps(item) + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a4dc43-d158-4b3e-b7cd-728954bce188",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks_final = []\n",
    "get_id_from_log = lambda x: x.split('/')[-1].split('.')[0]\n",
    "for k, v in inst_id_to_gt.items():\n",
    "    if len(v['FAIL_TO_PASS']) == 0:\n",
    "        continue\n",
    "    task = tasks[get_id_from_log(k)]\n",
    "    task['FAIL_TO_PASS'] = v['FAIL_TO_PASS']\n",
    "    task['PASS_TO_PASS'] = v['PASS_TO_PASS']\n",
    "    task['environment_setup_commit'] = version_to_setup_commit[task['version']]\n",
    "    tasks_final.append(task)\n",
    "print(f\"Final number of task instances: \", len(tasks_final))\n",
    "\n",
    "SAVE_PATH = \"../output.jsonl\" # TODO: Replace this with a path to a .json file to save the task instances\n",
    "dump_jsonl(tasks_final, SAVE_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
